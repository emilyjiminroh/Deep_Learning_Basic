{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f954bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "x_train = torch.FloatTensor([[1,2],[2,3],[3,4],[4,4],[5,3],[6,2]])\n",
    "y_train = torch.FloatTensor([[0],[0],[0],[1],[1],[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "418e0457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[ 0.07180151 -0.24788569]\n",
      " [-0.00799244  0.36927128]\n",
      " [ 0.26940462 -0.56188226]]\n",
      "Linear1 bias: [ 0.6524591  -0.27182695  0.3008919 ]\n",
      "Linear2 weights: [[-0.24823125 -0.22708847 -0.12710804]]\n",
      "Linear2 bias: [-0.01077786]\n",
      "==================================================\n",
      "Step: 100\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[ 0.01799865 -0.25842953]\n",
      " [-0.05478449  0.36001265]\n",
      " [ 0.2480991  -0.56724626]]\n",
      "Linear1 bias: [ 0.6489836  -0.27503365  0.29915845]\n",
      "Linear2 weights: [[-0.20657575 -0.1892891  -0.05649797]]\n",
      "Linear2 bias: [0.0543244]\n",
      "==================================================\n",
      "Step: 200\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.02459923 -0.26356906]\n",
      " [-0.09396023  0.35440037]\n",
      " [ 0.24205227 -0.56844246]]\n",
      "Linear1 bias: [ 0.64725965 -0.27694365  0.298774  ]\n",
      "Linear2 weights: [[-0.19064142 -0.18012598 -0.00074382]]\n",
      "Linear2 bias: [0.09000966]\n",
      "==================================================\n",
      "Step: 300\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.06184898 -0.26587778]\n",
      " [-0.13101618  0.35056612]\n",
      " [ 0.24678768 -0.5677353 ]]\n",
      "Linear1 bias: [ 0.6464899  -0.27818403  0.29899263]\n",
      "Linear2 weights: [[-0.19010411 -0.18845585  0.0485514 ]]\n",
      "Linear2 bias: [0.10989309]\n",
      "==================================================\n",
      "Step: 400\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.09663785 -0.26623964]\n",
      " [-0.16868173  0.3479538 ]\n",
      " [ 0.26042557 -0.56598616]]\n",
      "Linear1 bias: [ 0.6464095  -0.27891716  0.29950565]\n",
      "Linear2 weights: [[-0.19999108 -0.20902783  0.09588453]]\n",
      "Linear2 bias: [0.12092143]\n",
      "==================================================\n",
      "Step: 500\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.13029131 -0.26480776]\n",
      " [-0.20802005  0.3467092 ]\n",
      " [ 0.28199652 -0.563671  ]]\n",
      "Linear1 bias: [ 0.64699274 -0.27904987  0.30011237]\n",
      "Linear2 weights: [[-0.21770269 -0.23924726  0.14391863]]\n",
      "Linear2 bias: [0.12659965]\n",
      "==================================================\n",
      "Step: 600\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.16325355 -0.26137874]\n",
      " [-0.24892366  0.34746328]\n",
      " [ 0.310594   -0.5613172 ]]\n",
      "Linear1 bias: [ 0.64833504 -0.27831498  0.30057418]\n",
      "Linear2 weights: [[-0.24172123 -0.2776294   0.19423038]]\n",
      "Linear2 bias: [0.1285661]\n",
      "==================================================\n",
      "Step: 700\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.19548059 -0.25557864]\n",
      " [-0.29052103  0.35115388]\n",
      " [ 0.34490615 -0.559721  ]]\n",
      "Linear1 bias: [ 0.65058863 -0.2763431   0.3005485 ]\n",
      "Linear2 weights: [[-0.27101004 -0.32302946  0.2475729 ]]\n",
      "Linear2 bias: [0.12748407]\n",
      "==================================================\n",
      "Step: 800\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.22672458 -0.24699682]\n",
      " [-0.3316759   0.35876548]\n",
      " [ 0.38311768 -0.559967  ]]\n",
      "Linear1 bias: [ 0.6539151 -0.2727617  0.299596 ]\n",
      "Linear2 weights: [[-0.3047345  -0.37433404  0.3040269 ]]\n",
      "Linear2 bias: [0.12364121]\n",
      "==================================================\n",
      "Step: 900\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.25674403 -0.23529135]\n",
      " [-0.37147212  0.37104502]\n",
      " [ 0.42321196 -0.56322455]]\n",
      "Linear1 bias: [ 0.65844715 -0.2672945   0.297268  ]\n",
      "Linear2 weights: [[-0.3421503  -0.43043268  0.3632345 ]]\n",
      "Linear2 bias: [0.11736257]\n",
      "==================================================\n",
      "Step: 1000\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.28542644 -0.22026008]\n",
      " [-0.4094922   0.38830775]\n",
      " [ 0.4634725  -0.57041967]]\n",
      "Linear1 bias: [ 0.66426396 -0.25982082  0.29322356]\n",
      "Linear2 weights: [[-0.38257948 -0.49029288  0.42470977]]\n",
      "Linear2 bias: [0.10922024]\n",
      "==================================================\n",
      "Step: 1100\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.31282246 -0.20186962]\n",
      " [-0.4458348   0.41038933]\n",
      " [ 0.50283945 -0.5819831 ]]\n",
      "Linear1 bias: [ 0.67138356 -0.2503836   0.28730825]\n",
      "Linear2 weights: [[-0.4254204 -0.5530187  0.4880875]]\n",
      "Linear2 bias: [0.10003431]\n",
      "==================================================\n",
      "Step: 1200\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.33911827 -0.18024725]\n",
      " [-0.48096165  0.43671617]\n",
      " [ 0.54094887 -0.59780705]]\n",
      "Linear1 bias: [ 0.67976654 -0.23915888  0.27955475]\n",
      "Linear2 weights: [[-0.47016075 -0.61785775  0.553196  ]]\n",
      "Linear2 bias: [0.09073342]\n",
      "==================================================\n",
      "Step: 1300\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.36458135 -0.15565239]\n",
      " [-0.515489    0.46644098]\n",
      " [ 0.5779366  -0.6173706 ]]\n",
      "Linear1 bias: [ 0.68933004 -0.2264102   0.27013132]\n",
      "Linear2 weights: [[-0.5163795 -0.6841767  0.6199821]]\n",
      "Linear2 bias: [0.08218135]\n",
      "==================================================\n",
      "Step: 1400\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.38950688 -0.12844153]\n",
      " [-0.5500024   0.49859354]\n",
      " [ 0.6141789  -0.63992816]]\n",
      "Linear1 bias: [ 0.69995785 -0.21243948  0.25927782]\n",
      "Linear2 weights: [[-0.5637373  -0.7514302   0.68839425]]\n",
      "Linear2 bias: [0.07504772]\n",
      "==================================================\n",
      "Step: 1500\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.41417605 -0.09903508]\n",
      " [-0.5849345   0.53221947]\n",
      " [ 0.65008736 -0.66467476]]\n",
      "Linear1 bias: [ 0.7115132  -0.19754605  0.24725258]\n",
      "Linear2 weights: [[-0.61196065 -0.81914353  0.75829643]]\n",
      "Linear2 bias: [0.06975027]\n",
      "==================================================\n",
      "Step: 1600\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.4388294  -0.067889  ]\n",
      " [-0.6205144   0.56647974]\n",
      " [ 0.68598616 -0.6908595 ]]\n",
      "Linear1 bias: [ 0.72384846 -0.18199821  0.23429932]\n",
      "Linear2 weights: [[-0.66082245 -0.886901    0.82944167]]\n",
      "Linear2 bias: [0.06646243]\n",
      "==================================================\n",
      "Step: 1700\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.46365237 -0.035471  ]\n",
      " [-0.65678     0.6007035 ]\n",
      " [ 0.7220669  -0.7178446 ]]\n",
      "Linear1 bias: [ 0.7368107  -0.1660198   0.22063142]\n",
      "Linear2 weights: [[-0.71012515 -0.95434463  0.90148944]]\n",
      "Linear2 bias: [0.06516036]\n",
      "==================================================\n",
      "Step: 1800\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.48877135 -0.00224004]\n",
      " [-0.69362724  0.63439584]\n",
      " [ 0.7583943  -0.7451273 ]]\n",
      "Linear1 bias: [ 0.7502507  -0.14978857  0.20642777]\n",
      "Linear2 weights: [[-0.7596887  -1.021169    0.97404355]]\n",
      "Linear2 bias: [0.06568553]\n",
      "==================================================\n",
      "Step: 1900\n",
      "Current Value of [w,b]:\n",
      "Linear1 weights: [[-0.51425374  0.03137245]\n",
      " [-0.7308687   0.66722095]\n",
      " [ 0.7949361  -0.77233255]]\n",
      "Linear1 bias: [ 0.76402456 -0.13344197  0.1918355 ]\n",
      "Linear2 weights: [[-0.80934304 -1.0871209   1.046694  ]]\n",
      "Linear2 bias: [0.06780262]\n",
      "==================================================\n",
      "Model with [6,1] (expectation: 1) in sigmoid:  0.7471927404403687\n",
      "Model with [6,1] (expectation: 1) in np.round:  1.0\n"
     ]
    }
   ],
   "source": [
    "class class_BinaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(2,3)\n",
    "        self.linear2 = nn.Linear(3,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        return self.sigmoid(self.linear2(self.sigmoid(self.linear1(x))))\n",
    "    \n",
    "model_BinaryClassification = class_BinaryClassification()\n",
    "optimizer = torch.optim.SGD(model_BinaryClassification.parameters(), lr =0.01)\n",
    "\n",
    "for step in range(2000):\n",
    "    prediction = model_BinaryClassification(x_train)\n",
    "    cost = F.binary_cross_entropy(prediction,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step: {step}\")\n",
    "        print(\"Current Value of [w,b]:\")\n",
    "        print(\"Linear1 weights:\", model_BinaryClassification.linear1.weight.detach().numpy())\n",
    "        print(\"Linear1 bias:\", model_BinaryClassification.linear1.bias.detach().numpy())\n",
    "        print(\"Linear2 weights:\", model_BinaryClassification.linear2.weight.detach().numpy())\n",
    "        print(\"Linear2 bias:\", model_BinaryClassification.linear2.bias.detach().numpy())\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "# 모델 테스트\n",
    "x_test = torch.FloatTensor([[6,1]])\n",
    "model_test = model_BinaryClassification(x_test)\n",
    "print(\"Model with [6,1] (expectation: 1) in sigmoid: \",model_test.detach().item())\n",
    "model_test_binary = np.round(model_test>0.5).type(torch.float32)\n",
    "print(\"Model with [6,1] (expectation: 1) in np.round: \",model_test_binary.detach().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
